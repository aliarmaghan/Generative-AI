{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Which tools & packages we will be using today?\n\nPackages we're going to be using throughout this walkthrough will be\n\n- `unsloth`: Efficient fine-tuning and inference for LLMs — Specifically we will be using:\n    - `FastLanguageModel` module to optimize inference & fine-tuning\n    - `get_peft_model` to enable LoRa (Low-Rank Adaptation) fine-tuning\n- `peft`: Supports LoRA-based fine-tuning for large models.\n- Different Hugging Face modules:\n    - `transformers` from HuggingFace to work with our fine-tuning data and handle different model tasks\n    - `trl` Transformer Reinforcement Learning from HuggingFace which allows for supervised fine-tuning of the model — we will use the `SFFTrainer` wrapper\n    - `datasets` to fetch reasoning datasets from the Hugging Face Hub\n- `torch`: Deep learning framework used for training\n- `wandb`: Provides access to weights and biases for tracking our fine-tuning experiment ","metadata":{}},{"cell_type":"markdown","source":"## Before we get started — how to access the Hugging Face and Weights & Biases API\n\n### Set GPU accelerator\nWe are using Kaggle Notebooks because we have access to free GPUs. To enable GPU access, press on Settings > Accelerator > GPU T4 x2\n\n### How to access the Hugging Face API\n\n1. Register to Huggin Face if you have not already\n2. Go to [Hugging Face Tokens](https://huggingface.co/settings/tokens).\n3. Click **\"New Token\"**.\n4. Select **read/write** permissions if needed.\n5. Copy your **API key**.\n\n### Weights & Biases API key**\n1. Sign up at [Weights & Biases](https://wandb.ai/site).\n2. Go to [W&B Settings](https://wandb.ai/settings).\n3. Copy your **API key** from the \"API Keys\" section.\n\n### Add the API keys to Kaggle Notebooks\n1. Press on Add-ons > Secrets\n2. Add the API keys under `Hugging_Face_Token` and `wnb` respectively\n\nYou can now use this code to retrieve your API keys\n\n```py\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nhugging_face_token = user_secrets.get_secret(\"Hugging_Face_Token\")\nwnb_token = user_secrets.get_secret(\"wnb\")","metadata":{}},{"cell_type":"markdown","source":"## Install relevant packages","metadata":{}},{"cell_type":"code","source":"!pip install unsloth # install unsloth\n!pip install --force-reinstall --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git # Also get the latest version Unsloth!","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T06:20:44.394270Z","iopub.execute_input":"2025-02-26T06:20:44.394553Z","iopub.status.idle":"2025-02-26T06:23:51.058406Z","shell.execute_reply.started":"2025-02-26T06:20:44.394520Z","shell.execute_reply":"2025-02-26T06:23:51.057317Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting unsloth\n  Downloading unsloth-2025.2.15-py3-none-any.whl.metadata (57 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting unsloth_zoo>=2025.2.7 (from unsloth)\n  Downloading unsloth_zoo-2025.2.7-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (2.5.1+cu121)\nCollecting xformers>=0.0.27.post2 (from unsloth)\n  Downloading xformers-0.0.29.post3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\nCollecting bitsandbytes (from unsloth)\n  Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\nCollecting triton>=3.0.0 (from unsloth)\n  Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth) (24.2)\nCollecting tyro (from unsloth)\n  Downloading tyro-0.9.16-py3-none-any.whl.metadata (9.4 kB)\nCollecting transformers!=4.47.0,>=4.46.1 (from unsloth)\n  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (3.3.1)\nRequirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.2.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth) (5.9.5)\nRequirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.45.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth) (1.26.4)\nRequirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (1.2.1)\nCollecting trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 (from unsloth)\n  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.14.0)\nRequirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (3.20.3)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.29.0)\nRequirement already satisfied: hf_transfer in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.1.9)\nRequirement already satisfied: diffusers in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.31.0)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.20.1+cu121)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth) (0.4.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.17.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (2.32.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.16.0->unsloth) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.11.12)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->unsloth) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers!=4.47.0,>=4.46.1->unsloth) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers!=4.47.0,>=4.46.1->unsloth) (0.21.0)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (13.9.4)\nCollecting cut_cross_entropy (from unsloth_zoo>=2025.2.7->unsloth)\n  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2025.2.7->unsloth) (11.0.0)\nCollecting torch>=2.4.0 (from unsloth)\n  Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparselt-cu12==0.6.2 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting nvidia-nccl-cu12==2.21.5 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers->unsloth) (8.5.0)\nINFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\nCollecting torchvision (from unsloth)\n  Downloading torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\nRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (0.16)\nCollecting shtab>=1.5.6 (from tyro->unsloth)\n  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (4.4.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.18.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2025.1.31)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (2.19.1)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers->unsloth) (3.21.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->unsloth) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->unsloth) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2025.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth) (1.17.0)\nDownloading unsloth-2025.2.15-py3-none-any.whl (188 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.8/188.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.1/253.1 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading trl-0.15.2-py3-none-any.whl (318 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading unsloth_zoo-2025.2.7-py3-none-any.whl (107 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.1/107.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading xformers-0.0.29.post3-cp310-cp310-manylinux_2_28_x86_64.whl (43.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl (766.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl (7.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tyro-0.9.16-py3-none-any.whl (117 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\nDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\nInstalling collected packages: triton, nvidia-cusparselt-cu12, shtab, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, tyro, nvidia-cusolver-cu12, torch, cut_cross_entropy, transformers, trl, xformers, unsloth_zoo, torchvision, bitsandbytes, unsloth\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.23.4\n    Uninstalling nvidia-nccl-cu12-2.23.4:\n      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.7.77\n    Uninstalling nvidia-curand-cu12-10.3.7.77:\n      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.6.0.74\n    Uninstalling nvidia-cudnn-cu12-9.6.0.74:\n      Successfully uninstalled nvidia-cudnn-cu12-9.6.0.74\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n  Attempting uninstall: torch\n    Found existing installation: torch 2.5.1+cu121\n    Uninstalling torch-2.5.1+cu121:\n      Successfully uninstalled torch-2.5.1+cu121\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.47.0\n    Uninstalling transformers-4.47.0:\n      Successfully uninstalled transformers-4.47.0\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.20.1+cu121\n    Uninstalling torchvision-0.20.1+cu121:\n      Successfully uninstalled torchvision-0.20.1+cu121\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\npylibcugraph-cu12 24.10.0 requires pylibraft-cu12==24.10.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.10.0 requires rmm-cu12==24.10.*, but you have rmm-cu12 25.2.0 which is incompatible.\ntorchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.45.3 cut_cross_entropy-25.1.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 shtab-1.7.1 torch-2.6.0 torchvision-0.21.0 transformers-4.49.0 triton-3.2.0 trl-0.15.2 tyro-0.9.16 unsloth-2025.2.15 unsloth_zoo-2025.2.7 xformers-0.0.29.post3\nCollecting git+https://github.com/unslothai/unsloth.git\n  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-req-build-58nl84k9\n  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-req-build-58nl84k9\n  Resolved https://github.com/unslothai/unsloth.git to commit 2c0f50160e227936e0011d67e3bc2472c2089629\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nBuilding wheels for collected packages: unsloth\n  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for unsloth: filename=unsloth-2025.2.15-py3-none-any.whl size=189279 sha256=172f387d8d7b613721a1fe7378f7124a5624b125a74cf772e5bfa09d35b547e1\n  Stored in directory: /tmp/pip-ephem-wheel-cache-2y2ca_0_/wheels/ed/d4/e9/76fb290ee3df0a5fc21ce5c2c788e29e9607a2353d8342fd0d\nSuccessfully built unsloth\nInstalling collected packages: unsloth\n  Attempting uninstall: unsloth\n    Found existing installation: unsloth 2025.2.15\n    Uninstalling unsloth-2025.2.15:\n      Successfully uninstalled unsloth-2025.2.15\nSuccessfully installed unsloth-2025.2.15\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## Import all relevant packages throughout this walkthrough","metadata":{}},{"cell_type":"code","source":"# Modules for fine-tuning\nfrom unsloth import FastLanguageModel\nimport torch # Import PyTorch\nfrom trl import SFTTrainer # Trainer for supervised fine-tuning (SFT)\nfrom unsloth import is_bfloat16_supported # Checks if the hardware supports bfloat16 precision\n# Hugging Face modules\nfrom huggingface_hub import login # Lets you login to API\nfrom transformers import TrainingArguments # Defines training hyperparameters\nfrom datasets import load_dataset # Lets you load fine-tuning datasets\n# Import weights and biases\nimport wandb\n# Import kaggle secrets\nfrom kaggle_secrets import UserSecretsClient","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T06:23:55.959294Z","iopub.execute_input":"2025-02-26T06:23:55.959565Z","iopub.status.idle":"2025-02-26T06:24:24.470523Z","shell.execute_reply.started":"2025-02-26T06:23:55.959541Z","shell.execute_reply":"2025-02-26T06:24:24.469615Z"}},"outputs":[{"name":"stdout","text":"🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n🦥 Unsloth Zoo will now patch everything to make training faster!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Create API keys and login to Hugging Face and Weights and Biases","metadata":{}},{"cell_type":"code","source":"# Initialize Hugging Face & WnB tokens\nuser_secrets = UserSecretsClient() # from kaggle_secrets import UserSecretsClient\nhugging_face_token = user_secrets.get_secret(\"HF_Token\")\nwnb_token = user_secrets.get_secret(\"WnB\")\n\n# Login to Hugging Face\nlogin(hugging_face_token) # from huggingface_hub import login\n\n# Login to WnB\nwandb.login(key=wnb_token) # import wandb\nrun = wandb.init(\n    project='Fine-tune-DeepSeek-R1-Distill-Llama-8B on Medical COT Dataset_YouTube Walkthrough', \n    job_type=\"training\", \n    anonymous=\"allow\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T06:26:26.694514Z","iopub.execute_input":"2025-02-26T06:26:26.694828Z","iopub.status.idle":"2025-02-26T06:26:26.965114Z","shell.execute_reply.started":"2025-02-26T06:26:26.694774Z","shell.execute_reply":"2025-02-26T06:26:26.964267Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Loading DeepSeek R1 and the Tokenizer\n\n**What are we doing in this step?**\n\nIn this step, we **load the DeepSeek R1 model and its tokenizer** using `FastLanguageModel.from_pretrained()`. We also **configure key parameters** for efficient inference and fine-tuning. We will be using a distilled 8B version of R1 for faster computation.  \n\n**Key parameters explained**\n```py\nmax_seq_length = 2048  # Define the maximum sequence length a model can handle (i.e., number of tokens per input)\ndtype = None  # Default data type (usually auto-detected)\nload_in_4bit = True  # Enables 4-bit quantization – a memory-saving optimization\n```\n\n**Intuition behind 4-bit quantization**\n\nImagine compressing a **high-resolution image** to a smaller size—**it takes up less space but still looks good enough**. Similarly, **4-bit quantization reduces the precision of model weights**, making the model **smaller and faster while keeping most of its accuracy**. Instead of storing precise **32-bit or 16-bit numbers**, we compress them into **4-bit values**. This allows **large language models to run efficiently on consumer GPUs** without needing massive amounts of memory. ","metadata":{}},{"cell_type":"code","source":"# Set parameters\nmax_seq_length = 2048 # Define the maximum sequence length a model can handle (i.e. how many tokens can be processed at once)\ndtype = None # Set to default \nload_in_4bit = True # Enables 4 bit quantization — a memory saving optimization \n\n# Load the DeepSeek R1 model and tokenizer using unsloth — imported using: from unsloth import FastLanguageModel\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name=\"unsloth/DeepSeek-R1-Distill-Llama-8B\",  # Load the pre-trained DeepSeek R1 model (8B parameter version)\n    max_seq_length=max_seq_length, # Ensure the model can process up to 2048 tokens at once\n    dtype=dtype, # Use the default data type (e.g., FP16 or BF16 depending on hardware support)\n    load_in_4bit=load_in_4bit, # Load the model in 4-bit quantization to save memory\n    token=hugging_face_token, # Use hugging face token\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T06:48:46.926483Z","iopub.execute_input":"2025-02-26T06:48:46.926837Z","iopub.status.idle":"2025-02-26T06:48:55.620631Z","shell.execute_reply.started":"2025-02-26T06:48:46.926787Z","shell.execute_reply":"2025-02-26T06:48:55.619746Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2025.2.15: Fast Llama patching. Transformers: 4.49.0.\n   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"## Testing DeepSeek R1 on a medical use-case before fine-tuning\n\n\n### Defining a system prompt \nTo create a prompt style for the model, we will define a system prompt and include placeholders for the question and response generation. The prompt will guide the model to think step-by-step and provide a logical, accurate response.","metadata":{}},{"cell_type":"code","source":"# Define a system prompt under prompt_style \nprompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. \nWrite a response that appropriately completes the request. \nBefore answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n\n### Instruction:\nYou are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning. \nPlease answer the following medical question. \n\n### Question:\n{}\n\n### Response:\n<think>{}\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T06:27:52.724651Z","iopub.execute_input":"2025-02-26T06:27:52.724987Z","iopub.status.idle":"2025-02-26T06:27:52.729721Z","shell.execute_reply.started":"2025-02-26T06:27:52.724960Z","shell.execute_reply":"2025-02-26T06:27:52.729019Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### Running inference on the model\n\nIn this step, we **test the DeepSeek R1 model** by providing a **medical question** and generating a response.  \nThe process involves the following steps:\n\n1. **Define a test question** related to a medical case.\n2. **Format the question using the structured prompt (`prompt_style`)** to ensure the model follows a logical reasoning process.\n3. **Tokenize the input and move it to the GPU (`cuda`)** for faster inference.\n4. **Generate a response using the model**, specifying key parameters like `max_new_tokens=1200` (limits response length).\n5. **Decode the output tokens back into text** to obtain the final readable answer.|","metadata":{}},{"cell_type":"code","source":"# Creating a test medical question for inference\nquestion = \"\"\"A 61-year-old woman with a long history of involuntary urine loss during activities like coughing or \n              sneezing but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings, \n              what would cystometry most likely reveal about her residual volume and detrusor contractions?\"\"\"\n\n# Enable optimized inference mode for Unsloth models (improves speed and efficiency)\nFastLanguageModel.for_inference(model)  # Unsloth has 2x faster inference!\n\n# Format the question using the structured prompt (`prompt_style`) and tokenize it\ninputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")  # Convert input to PyTorch tensor & move to GPU\n\n# Generate a response using the model\noutputs = model.generate(\n    input_ids=inputs.input_ids, # Tokenized input question\n    attention_mask=inputs.attention_mask, # Attention mask to handle padding\n    max_new_tokens=1200, # Limit response length to 1200 tokens (to prevent excessive output)\n    use_cache=True, # Enable caching for faster inference\n)\n\n# Decode the generated output tokens into human-readable text\nresponse = tokenizer.batch_decode(outputs)\n\n# Extract and print only the relevant response part (after \"### Response:\")\nprint(response[0].split(\"### Response:\")[1])  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T06:28:05.218263Z","iopub.execute_input":"2025-02-26T06:28:05.218563Z","iopub.status.idle":"2025-02-26T06:28:51.313376Z","shell.execute_reply.started":"2025-02-26T06:28:05.218540Z","shell.execute_reply":"2025-02-26T06:28:51.312303Z"}},"outputs":[{"name":"stdout","text":"\n<think>\nOkay, so I'm trying to figure out what the cystometry would show for this 61-year-old woman. Let me start by going through the details given.\n\nFirst, the patient has a history of involuntary urine loss during activities like coughing or sneezing. That makes me think of stress urinary incontinence. I remember that stress incontinence is usually due to the bladder not fully emptying, especially when there's increased abdominal pressure, like from coughing.\n\nShe doesn't leak at night, which is interesting. Nocturnal enuresis is more common in children, but it can also happen in adults, especially if there's a neurological issue. But here, the main issue seems to be during activities that cause increased pressure, so maybe it's more of a physical issue rather than something related to sleep.\n\nShe underwent a gynecological exam and Q-tip test. I'm not entirely sure what the Q-tip test entails, but I think it's a diagnostic tool used to check for urethral obstruction. The Q-tip is a catheter that's passed into the urethra and then removed to see if it's easy to withdraw, which would indicate if there's resistance (like a stricture or obstruction). If it's hard to remove, it might suggest an obstruction.\n\nSo, putting this together, if the Q-tip test shows that the urethra is easily passable, then maybe the issue isn't with the urethral narrowing. If it's difficult, then perhaps there's a urethral stricture or some obstruction.\n\nNow, moving to cystometry. Cystometry is a test where they fill the bladder and measure how much it holds (residual volume) and how it contracts (detrusor contractions). If the bladder doesn't empty completely, especially when there's increased pressure, it can lead to leakage.\n\nGiven that she has involuntary loss during activities that increase abdominal pressure, it's likely that her bladder isn't emptying properly. So, during cystometry, they would measure her residual volume. If the residual volume is high, it suggests that the bladder didn't empty completely after urination. Additionally, they would look at detrusor contractions, which are the contractions of the bladder muscle that help empty the bladder.\n\nIf the detrusor contractions are weak, it might indicate that the bladder isn't emptying effectively, contributing to the incontinence. On the other hand, if there's resistance during the Q-tip test, it might suggest a urethral issue, but since the main problem is during activities that increase pressure, the bladder's function is more likely the culprit.\n\nSo, putting it all together, cystometry would likely show an increased residual volume because the bladder isn't emptying completely, and possibly weak detrusor contractions, contributing to the stress urinary incontinence.\n</think>\n\n**Answer:**\n\nThe cystometry for this 61-year-old woman with a history of involuntary urine loss during activities like coughing or sneezing would most likely reveal an increased residual volume and weak detrusor contractions. \n\n**Explanation:**\n\n1. **Residual Volume:** The test would show a high residual volume, indicating that the bladder does not empty completely after urination. This is a key factor in stress urinary incontinence, as the bladder doesn't fully empty, leading to leakage during activities that increase abdominal pressure.\n\n2. **Detrusor Contractions:** The test would also reveal weak detrusor contractions. Weak contractions of the bladder muscle contribute to the inability of the bladder to fully empty, further exacerbating the incontinence.\n\nIn summary, the findings from cystometry would support the diagnosis of stress urinary incontinence, with the bladder's incomplete emptying and weak contractions as contributing factors.<｜end▁of▁sentence｜>\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"print(response[0])  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T06:30:28.186355Z","iopub.execute_input":"2025-02-26T06:30:28.186663Z","iopub.status.idle":"2025-02-26T06:30:28.193619Z","shell.execute_reply.started":"2025-02-26T06:30:28.186641Z","shell.execute_reply":"2025-02-26T06:30:28.192878Z"}},"outputs":[{"name":"stdout","text":"<｜begin▁of▁sentence｜>Below is an instruction that describes a task, paired with an input that provides further context. \nWrite a response that appropriately completes the request. \nBefore answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n\n### Instruction:\nYou are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning. \nPlease answer the following medical question. \n\n### Question:\nA 61-year-old woman with a long history of involuntary urine loss during activities like coughing or \n              sneezing but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings, \n              what would cystometry most likely reveal about her residual volume and detrusor contractions?\n\n### Response:\n<think>\nOkay, so I'm trying to figure out what the cystometry would show for this 61-year-old woman. Let me start by going through the details given.\n\nFirst, the patient has a history of involuntary urine loss during activities like coughing or sneezing. That makes me think of stress urinary incontinence. I remember that stress incontinence is usually due to the bladder not fully emptying, especially when there's increased abdominal pressure, like from coughing.\n\nShe doesn't leak at night, which is interesting. Nocturnal enuresis is more common in children, but it can also happen in adults, especially if there's a neurological issue. But here, the main issue seems to be during activities that cause increased pressure, so maybe it's more of a physical issue rather than something related to sleep.\n\nShe underwent a gynecological exam and Q-tip test. I'm not entirely sure what the Q-tip test entails, but I think it's a diagnostic tool used to check for urethral obstruction. The Q-tip is a catheter that's passed into the urethra and then removed to see if it's easy to withdraw, which would indicate if there's resistance (like a stricture or obstruction). If it's hard to remove, it might suggest an obstruction.\n\nSo, putting this together, if the Q-tip test shows that the urethra is easily passable, then maybe the issue isn't with the urethral narrowing. If it's difficult, then perhaps there's a urethral stricture or some obstruction.\n\nNow, moving to cystometry. Cystometry is a test where they fill the bladder and measure how much it holds (residual volume) and how it contracts (detrusor contractions). If the bladder doesn't empty completely, especially when there's increased pressure, it can lead to leakage.\n\nGiven that she has involuntary loss during activities that increase abdominal pressure, it's likely that her bladder isn't emptying properly. So, during cystometry, they would measure her residual volume. If the residual volume is high, it suggests that the bladder didn't empty completely after urination. Additionally, they would look at detrusor contractions, which are the contractions of the bladder muscle that help empty the bladder.\n\nIf the detrusor contractions are weak, it might indicate that the bladder isn't emptying effectively, contributing to the incontinence. On the other hand, if there's resistance during the Q-tip test, it might suggest a urethral issue, but since the main problem is during activities that increase pressure, the bladder's function is more likely the culprit.\n\nSo, putting it all together, cystometry would likely show an increased residual volume because the bladder isn't emptying completely, and possibly weak detrusor contractions, contributing to the stress urinary incontinence.\n</think>\n\n**Answer:**\n\nThe cystometry for this 61-year-old woman with a history of involuntary urine loss during activities like coughing or sneezing would most likely reveal an increased residual volume and weak detrusor contractions. \n\n**Explanation:**\n\n1. **Residual Volume:** The test would show a high residual volume, indicating that the bladder does not empty completely after urination. This is a key factor in stress urinary incontinence, as the bladder doesn't fully empty, leading to leakage during activities that increase abdominal pressure.\n\n2. **Detrusor Contractions:** The test would also reveal weak detrusor contractions. Weak contractions of the bladder muscle contribute to the inability of the bladder to fully empty, further exacerbating the incontinence.\n\nIn summary, the findings from cystometry would support the diagnosis of stress urinary incontinence, with the bladder's incomplete emptying and weak contractions as contributing factors.<｜end▁of▁sentence｜>\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":">**Before starting fine-tuning — why are we fine-tuning in the first place?**\n>\n> Even without fine-tuning, our model successfully generated a chain of thought and provided reasoning before delivering the final answer. The reasoning process is encapsulated within the `<think>` `</think>` tags. So, why do we still need fine-tuning? The reasoning process, while detailed, was long-winded and not concise. Additionally, we want the final answer to be consistent in a certain style. \n\n","metadata":{}},{"cell_type":"markdown","source":"## Fine-tuning step by step\n\n### Step 1 — Update the system prompt \nWe will slightly change the prompt style for processing the dataset by adding the third placeholder for the complex chain of thought column. `</think>`","metadata":{}},{"cell_type":"code","source":"# Updated training prompt style to add </think> tag \ntrain_prompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. \nWrite a response that appropriately completes the request. \nBefore answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n\n### Instruction:\nYou are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning. \nPlease answer the following medical question. \n\n### Question:\n{}\n\n### Response:\n<think>\n{}\n</think>\n{}\"\"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T06:32:58.585293Z","iopub.execute_input":"2025-02-26T06:32:58.585582Z","iopub.status.idle":"2025-02-26T06:32:58.590268Z","shell.execute_reply.started":"2025-02-26T06:32:58.585559Z","shell.execute_reply":"2025-02-26T06:32:58.589412Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"### Step 2 — Download the fine-tuning dataset and format it for fine-tuning\n\nWe will use the Medical O1 Reasoninng SFT found here on [Hugging Face](https://huggingface.co/datasets/FreedomIntelligence/medical-o1-reasoning-SFT). From the authors: This dataset is used to fine-tune HuatuoGPT-o1, a medical LLM designed for advanced medical reasoning. This dataset is constructed using GPT-4o, which searches for solutions to verifiable medical problems and validates them through a medical verifier.","metadata":{}},{"cell_type":"code","source":"# Download the dataset using Hugging Face — function imported using from datasets import load_dataset\ndataset = load_dataset(\"FreedomIntelligence/medical-o1-reasoning-SFT\",\"en\", split = \"train[0:500]\",trust_remote_code=True) # Keep only first 500 rows\ndataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T06:33:18.861347Z","iopub.execute_input":"2025-02-26T06:33:18.861673Z","iopub.status.idle":"2025-02-26T06:33:22.234056Z","shell.execute_reply.started":"2025-02-26T06:33:18.861646Z","shell.execute_reply":"2025-02-26T06:33:22.233401Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/1.65k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"705f2240253b41479a68bb204b94d7dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"medical_o1_sft.json:   0%|          | 0.00/74.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6d52acc7ba445368312b89df56e3aeb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/25371 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d31bd1bb621b44078259b15c16acf684"}},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['Question', 'Complex_CoT', 'Response'],\n    num_rows: 500\n})"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# Show an entry from the dataset\ndataset[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T06:41:59.486047Z","iopub.execute_input":"2025-02-26T06:41:59.486395Z","iopub.status.idle":"2025-02-26T06:41:59.493391Z","shell.execute_reply.started":"2025-02-26T06:41:59.486370Z","shell.execute_reply":"2025-02-26T06:41:59.492636Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"{'Question': 'A 61-year-old woman with a long history of involuntary urine loss during activities like coughing or sneezing but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings, what would cystometry most likely reveal about her residual volume and detrusor contractions?',\n 'Complex_CoT': \"Okay, let's think about this step by step. There's a 61-year-old woman here who's been dealing with involuntary urine leakages whenever she's doing something that ups her abdominal pressure like coughing or sneezing. This sounds a lot like stress urinary incontinence to me. Now, it's interesting that she doesn't have any issues at night; she isn't experiencing leakage while sleeping. This likely means her bladder's ability to hold urine is fine when she isn't under physical stress. Hmm, that's a clue that we're dealing with something related to pressure rather than a bladder muscle problem. \\n\\nThe fact that she underwent a Q-tip test is intriguing too. This test is usually done to assess urethral mobility. In stress incontinence, a Q-tip might move significantly, showing urethral hypermobility. This kind of movement often means there's a weakness in the support structures that should help keep the urethra closed during increases in abdominal pressure. So, that's aligning well with stress incontinence.\\n\\nNow, let's think about what would happen during cystometry. Since stress incontinence isn't usually about sudden bladder contractions, I wouldn't expect to see involuntary detrusor contractions during this test. Her bladder isn't spasming or anything; it's more about the support structure failing under stress. Plus, she likely empties her bladder completely because stress incontinence doesn't typically involve incomplete emptying. So, her residual volume should be pretty normal. \\n\\nAll in all, it seems like if they do a cystometry on her, it will likely show a normal residual volume and no involuntary contractions. Yup, I think that makes sense given her symptoms and the typical presentations of stress urinary incontinence.\",\n 'Response': 'Cystometry in this case of stress urinary incontinence would most likely reveal a normal post-void residual volume, as stress incontinence typically does not involve issues with bladder emptying. Additionally, since stress urinary incontinence is primarily related to physical exertion and not an overactive bladder, you would not expect to see any involuntary detrusor contractions during the test.'}"},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":">**Next step is to structure the fine-tuning dataset according to train prompt style—why?**\n>\n> - Each question is paired with chain-of-thought reasoning and the final response.\n> - Ensures every training example follows a consistent pattern.\n> - Prevents the model from continuing beyond the expected response lengt by adding the EOS token.","metadata":{}},{"cell_type":"code","source":"# We need to format the dataset to fit our prompt training style \nEOS_TOKEN = tokenizer.eos_token  # Define EOS_TOKEN which the model when to stop generating text during training\nEOS_TOKEN","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T06:35:34.777392Z","iopub.execute_input":"2025-02-26T06:35:34.777722Z","iopub.status.idle":"2025-02-26T06:35:34.784362Z","shell.execute_reply.started":"2025-02-26T06:35:34.777693Z","shell.execute_reply":"2025-02-26T06:35:34.783546Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"'<｜end▁of▁sentence｜>'"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"# Define formatting prompt function\ndef formatting_prompts_func(examples):  # Takes a batch of dataset examples as input\n    inputs = examples[\"Question\"]       # Extracts the medical question from the dataset\n    cots = examples[\"Complex_CoT\"]      # Extracts the chain-of-thought reasoning (logical step-by-step explanation)\n    outputs = examples[\"Response\"]      # Extracts the final model-generated response (answer)\n    \n    texts = []  # Initializes an empty list to store the formatted prompts\n    \n    # Iterate over the dataset, formatting each question, reasoning step, and response\n    for input, cot, output in zip(inputs, cots, outputs):  \n        text = train_prompt_style.format(input, cot, output) + EOS_TOKEN  # Insert values into prompt template & append EOS token\n        texts.append(text)  # Add the formatted text to the list\n\n    return {\n        \"text\": texts,  # Return the newly formatted dataset with a \"text\" column containing structured prompts\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T06:44:51.278517Z","iopub.execute_input":"2025-02-26T06:44:51.279058Z","iopub.status.idle":"2025-02-26T06:44:51.285441Z","shell.execute_reply.started":"2025-02-26T06:44:51.278925Z","shell.execute_reply":"2025-02-26T06:44:51.284740Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Update dataset formatting\ndataset_finetune = dataset.map(formatting_prompts_func, batched = True)\ndataset_finetune[\"text\"][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T06:45:01.049113Z","iopub.execute_input":"2025-02-26T06:45:01.049395Z","iopub.status.idle":"2025-02-26T06:45:01.101631Z","shell.execute_reply.started":"2025-02-26T06:45:01.049374Z","shell.execute_reply":"2025-02-26T06:45:01.101035Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c8b19e732c74ea7a2b6725d0270b441"}},"metadata":{}},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"\"Below is an instruction that describes a task, paired with an input that provides further context. \\nWrite a response that appropriately completes the request. \\nBefore answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\\n\\n### Instruction:\\nYou are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning. \\nPlease answer the following medical question. \\n\\n### Question:\\nA 61-year-old woman with a long history of involuntary urine loss during activities like coughing or sneezing but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings, what would cystometry most likely reveal about her residual volume and detrusor contractions?\\n\\n### Response:\\n<think>\\nOkay, let's think about this step by step. There's a 61-year-old woman here who's been dealing with involuntary urine leakages whenever she's doing something that ups her abdominal pressure like coughing or sneezing. This sounds a lot like stress urinary incontinence to me. Now, it's interesting that she doesn't have any issues at night; she isn't experiencing leakage while sleeping. This likely means her bladder's ability to hold urine is fine when she isn't under physical stress. Hmm, that's a clue that we're dealing with something related to pressure rather than a bladder muscle problem. \\n\\nThe fact that she underwent a Q-tip test is intriguing too. This test is usually done to assess urethral mobility. In stress incontinence, a Q-tip might move significantly, showing urethral hypermobility. This kind of movement often means there's a weakness in the support structures that should help keep the urethra closed during increases in abdominal pressure. So, that's aligning well with stress incontinence.\\n\\nNow, let's think about what would happen during cystometry. Since stress incontinence isn't usually about sudden bladder contractions, I wouldn't expect to see involuntary detrusor contractions during this test. Her bladder isn't spasming or anything; it's more about the support structure failing under stress. Plus, she likely empties her bladder completely because stress incontinence doesn't typically involve incomplete emptying. So, her residual volume should be pretty normal. \\n\\nAll in all, it seems like if they do a cystometry on her, it will likely show a normal residual volume and no involuntary contractions. Yup, I think that makes sense given her symptoms and the typical presentations of stress urinary incontinence.\\n</think>\\nCystometry in this case of stress urinary incontinence would most likely reveal a normal post-void residual volume, as stress incontinence typically does not involve issues with bladder emptying. Additionally, since stress urinary incontinence is primarily related to physical exertion and not an overactive bladder, you would not expect to see any involuntary detrusor contractions during the test.<｜end▁of▁sentence｜>\""},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"### Step 3 — Setting up the model using LoRA\n\n**An intuitive explanation of LoRA** \n\nLarge language models (LLMs) have **millions or even billions of weights** that determine how they process and generate text. When fine-tuning a model, we usually update all these weights, which **requires massive computational resources and memory**.\n\nLoRA (**Low-Rank Adaptation**) allows to fine-tune efficiently by:\n\n- Instead of modifying all weights, **LoRA adds small, trainable adapters** to specific layers.  \n- These adapters **capture task-specific knowledge** while leaving the original model unchanged.  \n- This reduces the number of trainable parameters **by more than 90%**, making fine-tuning **faster and more memory-efficient**.  \n\nThink of an LLM as a **complex factory**. Instead of rebuilding the entire factory to produce a new product, LoRA **adds small, specialized tools** to existing machines. This allows the factory to adapt quickly **without disrupting its core structure**.\n\nFor a more technical explanation, check out this tutorial by [Sebastian Raschka](https://www.youtube.com/watch?v=rgmJep4Sb4&t).\n\nBelow, we will use the `get_peft_model()` function which stands for Parameter-Efficient Fine-Tuning — this function wraps the base model (`model`) with LoRA modifications, ensuring that only specific parameters are trained.","metadata":{}},{"cell_type":"code","source":"# Apply LoRA (Low-Rank Adaptation) fine-tuning to the model \nmodel_lora = FastLanguageModel.get_peft_model(\n    model,\n    r=16,  # LoRA rank: Determines the size of the trainable adapters (higher = more parameters, lower = more efficiency)\n    target_modules=[  # List of transformer layers where LoRA adapters will be applied\n        \"q_proj\",   # Query projection in the self-attention mechanism\n        \"k_proj\",   # Key projection in the self-attention mechanism\n        \"v_proj\",   # Value projection in the self-attention mechanism\n        \"o_proj\",   # Output projection from the attention layer\n        \"gate_proj\",  # Used in feed-forward layers (MLP)\n        \"up_proj\",    # Part of the transformer’s feed-forward network (FFN)\n        \"down_proj\",  # Another part of the transformer’s FFN\n    ],\n    lora_alpha=16,  # Scaling factor for LoRA updates (higher values allow more influence from LoRA layers)\n    lora_dropout=0,  # Dropout rate for LoRA layers (0 means no dropout, full retention of information)\n    bias=\"none\",  # Specifies whether LoRA layers should learn bias terms (setting to \"none\" saves memory)\n    use_gradient_checkpointing=\"unsloth\",  # Saves memory by recomputing activations instead of storing them (recommended for long-context fine-tuning)\n    random_state=3407,  # Sets a seed for reproducibility, ensuring the same fine-tuning behavior across runs\n    use_rslora=False,  # Whether to use Rank-Stabilized LoRA (disabled here, meaning fixed-rank LoRA is used)\n    loftq_config=None,  # Low-bit Fine-Tuning Quantization (LoFTQ) is disabled in this configuration\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T06:49:05.871495Z","iopub.execute_input":"2025-02-26T06:49:05.871884Z","iopub.status.idle":"2025-02-26T06:49:12.371017Z","shell.execute_reply.started":"2025-02-26T06:49:05.871854Z","shell.execute_reply":"2025-02-26T06:49:12.370118Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"Now, we initialize `SFTTrainer`, a supervised fine-tuning trainer from `trl` (Transformer Reinforcement Learning), to fine-tune our model efficiently on a dataset.","metadata":{}},{"cell_type":"code","source":"# Initialize the fine-tuning trainer — Imported using from trl import SFTTrainer\ntrainer = SFTTrainer(\n    model=model_lora,  # The model to be fine-tuned\n    tokenizer=tokenizer,  # Tokenizer to process text inputs\n    train_dataset=dataset_finetune,  # Dataset used for training\n    dataset_text_field=\"text\",  # Specifies which field in the dataset contains training text\n    max_seq_length=max_seq_length,  # Defines the maximum sequence length for inputs\n    dataset_num_proc=2,  # Uses 2 CPU threads to speed up data preprocessing\n\n    # Define training arguments\n    args=TrainingArguments(\n        per_device_train_batch_size=2,  # Number of examples processed per device (GPU) at a time\n        gradient_accumulation_steps=4,  # Accumulate gradients over 4 steps before updating weights\n        num_train_epochs=1, # Full fine-tuning run\n        warmup_steps=5,  # Gradually increases learning rate for the first 5 steps\n        max_steps=60,  # Limits training to 60 steps (useful for debugging; increase for full fine-tuning)\n        learning_rate=2e-4,  # Learning rate for weight updates (tuned for LoRA fine-tuning)\n        fp16=not is_bfloat16_supported(),  # Use FP16 (if BF16 is not supported) to speed up training\n        bf16=is_bfloat16_supported(),  # Use BF16 if supported (better numerical stability on newer GPUs)\n        logging_steps=10,  # Logs training progress every 10 steps\n        optim=\"adamw_8bit\",  # Uses memory-efficient AdamW optimizer in 8-bit mode\n        weight_decay=0.01,  # Regularization to prevent overfitting\n        lr_scheduler_type=\"linear\",  # Uses a linear learning rate schedule\n        seed=3407,  # Sets a fixed seed for reproducibility\n        output_dir=\"outputs\",  # Directory where fine-tuned model checkpoints will be saved\n    ),\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T06:49:12.372300Z","iopub.execute_input":"2025-02-26T06:49:12.372558Z","iopub.status.idle":"2025-02-26T06:49:18.232753Z","shell.execute_reply.started":"2025-02-26T06:49:12.372534Z","shell.execute_reply":"2025-02-26T06:49:18.232043Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Converting train dataset to ChatML (num_proc=2):   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1176244a86ae4aa897487728136bbb48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Applying chat template to train dataset (num_proc=2):   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20083c6ad49b46f2a78ae203e79f2d31"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing train dataset (num_proc=2):   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ce4773de01642ca856549b8b84d4876"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Truncating train dataset (num_proc=2):   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d5bbabddcf14fc0b046983fb57b5258"}},"metadata":{}}],"execution_count":24},{"cell_type":"markdown","source":"## Step 4 — Model training! \n\nThis should take around 30 to 40 minutes — we can then check out our training results on Weights and Biases","metadata":{}},{"cell_type":"code","source":"# Start the fine-tuning process\ntrainer_stats = trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T06:54:53.422227Z","iopub.execute_input":"2025-02-26T06:54:53.422570Z","iopub.status.idle":"2025-02-26T07:17:44.705586Z","shell.execute_reply.started":"2025-02-26T06:54:53.422544Z","shell.execute_reply":"2025-02-26T07:17:44.704884Z"}},"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n   \\\\   /|    Num examples = 500 | Num Epochs = 1\nO^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n\\        /    Total batch size = 8 | Total steps = 60\n \"-____-\"     Number of trainable parameters = 41,943,040\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [60/60 22:14, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>1.918800</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.461500</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.402300</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.308800</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.344300</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.314000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"# Save the fine-tuned model\nwandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T07:18:49.393637Z","iopub.execute_input":"2025-02-26T07:18:49.393988Z","iopub.status.idle":"2025-02-26T07:18:51.107520Z","shell.execute_reply.started":"2025-02-26T07:18:49.393961Z","shell.execute_reply":"2025-02-26T07:18:51.106870Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▂▄▅▇██</td></tr><tr><td>train/global_step</td><td>▁▂▄▅▇██</td></tr><tr><td>train/grad_norm</td><td>█▂▂▁▂▂</td></tr><tr><td>train/learning_rate</td><td>█▇▅▄▂▁</td></tr><tr><td>train/loss</td><td>█▃▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>1.8014312853602304e+16</td></tr><tr><td>train/epoch</td><td>0.96</td></tr><tr><td>train/global_step</td><td>60</td></tr><tr><td>train/grad_norm</td><td>0.26025</td></tr><tr><td>train/learning_rate</td><td>0</td></tr><tr><td>train/loss</td><td>1.314</td></tr><tr><td>train_loss</td><td>1.45829</td></tr><tr><td>train_runtime</td><td>1369.0851</td></tr><tr><td>train_samples_per_second</td><td>0.351</td></tr><tr><td>train_steps_per_second</td><td>0.044</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">robust-rain-2</strong> at: <a href='https://wandb.ai/maarmaghan-aligarh-muslim-university/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset_YouTube%20Walkthrough/runs/iep9eyvl' target=\"_blank\">https://wandb.ai/maarmaghan-aligarh-muslim-university/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset_YouTube%20Walkthrough/runs/iep9eyvl</a><br> View project at: <a href='https://wandb.ai/maarmaghan-aligarh-muslim-university/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset_YouTube%20Walkthrough' target=\"_blank\">https://wandb.ai/maarmaghan-aligarh-muslim-university/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset_YouTube%20Walkthrough</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250226_062546-iep9eyvl/logs</code>"},"metadata":{}}],"execution_count":26},{"cell_type":"markdown","source":"## Step 5 — Run model inference after fine-tuning","metadata":{}},{"cell_type":"code","source":"question = \"\"\"A 61-year-old woman with a long history of involuntary urine loss during activities like coughing or sneezing \n              but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings, \n              what would cystometry most likely reveal about her residual volume and detrusor contractions?\"\"\"\n\n# Load the inference model using FastLanguageModel (Unsloth optimizes for speed)\nFastLanguageModel.for_inference(model_lora)  # Unsloth has 2x faster inference!\n\n# Tokenize the input question with a specific prompt format and move it to the GPU\ninputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n\n# Generate a response using LoRA fine-tuned model with specific parameters\noutputs = model_lora.generate(\n    input_ids=inputs.input_ids,          # Tokenized input IDs\n    attention_mask=inputs.attention_mask, # Attention mask for padding handling\n    max_new_tokens=1200,                  # Maximum length for generated response\n    use_cache=True,                        # Enable cache for efficient generation\n)\n\n# Decode the generated response from tokenized format to readable text\nresponse = tokenizer.batch_decode(outputs)\n\n# Extract and print only the model's response part after \"### Response:\"\nprint(response[0].split(\"### Response:\")[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T07:19:44.798730Z","iopub.execute_input":"2025-02-26T07:19:44.799114Z","iopub.status.idle":"2025-02-26T07:20:27.885018Z","shell.execute_reply.started":"2025-02-26T07:19:44.799085Z","shell.execute_reply":"2025-02-26T07:20:27.884081Z"}},"outputs":[{"name":"stdout","text":"\n<think>\nOkay, so let's think about this. We have a 61-year-old woman who's been dealing with involuntary urine loss during things like coughing or sneezing, but she's not leaking at night. That suggests she might have some kind of problem with her pelvic floor muscles or maybe her bladder.\n\nNow, she's got a gynecological exam and a Q-tip test. Let's break that down. The Q-tip test is usually used to check for urethral obstruction. If it's positive, that means there's something blocking the urethra, like a urethral stricture or something else.\n\nIf she's experiencing involuntary loss during activities, like coughing, it might mean her pelvic floor muscles aren't working properly. They might not be contracting when they should to support the bladder. This could lead to a problem with the urethral sphincter, which controls the release of urine.\n\nBut let's not jump to conclusions. It's important to look at what's happening in the bladder. We need to know about her residual volume and detrusor contractions. These are key factors in understanding how her bladder is functioning.\n\nIf her bladder's capacity is low, that could mean she doesn't have enough space to hold the urine, leading to frequent urination. If her detrusor contractions are weak, that might explain why she's not able to hold her urine during activities.\n\nNow, let's think about cystometry. This test is crucial because it gives us direct insights into the bladder's function. It can show how much residual volume the bladder holds and how strong the contractions are.\n\nIf her bladder's capacity is low, it would mean she's holding less urine, which could explain why she's experiencing these involuntary losses. And if her detrusor contractions are weak, that would support the idea that her pelvic floor muscles aren't working as they should.\n\nPutting it all together, if she has a low bladder capacity, her bladder can't hold much urine. And if her detrusor contractions are weak, she might not be able to hold the urine until she can get to a toilet. This combination would likely mean her bladder is underactive and not effectively controlling the release of urine, leading to the involuntary losses she's experiencing.\n\nSo, based on her symptoms and the Q-tip test, it's reasonable to expect that her cystometry would show a low residual volume and weak detrusor contractions. These findings would align with the idea that she's struggling with bladder control due to weak pelvic floor muscle function and a limited bladder capacity.\n</think>\nBased on the 61-year-old woman's symptoms of involuntary urine loss during activities like coughing or sneezing, and the results from her Q-tip test, it is most likely that her cystometry will reveal a low residual volume and weak detrusor contractions. These findings suggest that her bladder's capacity is limited and that her detrusor contractions, which are crucial for bladder emptying, are not functioning properly. This combination of low bladder capacity and weak detrusor contractions aligns with the symptoms of a weak pelvic floor muscle function, which could be contributing to her involuntary urine loss.<｜end▁of▁sentence｜>\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"question = \"\"\"A 59-year-old man presents with a fever, chills, night sweats, and generalized fatigue, \n              and is found to have a 12 mm vegetation on the aortic valve. Blood cultures indicate gram-positive, catalase-negative, \n              gamma-hemolytic cocci in chains that do not grow in a 6.5% NaCl medium. \n              What is the most likely predisposing factor for this patient's condition?\"\"\"\n\n# Tokenize the input question with a specific prompt format and move it to the GPU\ninputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n\n# Generate a response using LoRA fine-tuned model with specific parameters\noutputs = model_lora.generate(\n    input_ids=inputs.input_ids,          # Tokenized input IDs\n    attention_mask=inputs.attention_mask, # Attention mask for padding handling\n    max_new_tokens=1200,                  # Maximum length for generated response\n    use_cache=True,                        # Enable cache for efficient generation\n)\n\n# Decode the generated response from tokenized format to readable text\nresponse = tokenizer.batch_decode(outputs)\n\n# Extract and print only the model's response part after \"### Response:\"\nprint(response[0].split(\"### Response:\")[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T07:21:26.687667Z","iopub.execute_input":"2025-02-26T07:21:26.688027Z","iopub.status.idle":"2025-02-26T07:22:13.599397Z","shell.execute_reply.started":"2025-02-26T07:21:26.687996Z","shell.execute_reply":"2025-02-26T07:22:13.598444Z"}},"outputs":[{"name":"stdout","text":"\n<think>\nOkay, let's see what we have here. We have a 59-year-old man who's feeling pretty unwell with fever, chills, night sweats, and fatigue. That's classic for a systemic infection, like endocarditis. Now, the kicker here is that they've found a 12 mm vegetation on his aortic valve. That's a big clue because that's pretty big for a vegetation. Usually, vegetation size correlates with the risk of complications, like embolization or valve damage.\n\nAnd then we have the blood culture results. They're showing gram-positive, catalase-negative, gamma-hemolytic cocci in chains that don't grow in a 6.5% NaCl medium. Hmm, let's think about that for a second. The key here is the lack of growth in 6.5% NaCl. That's telling us that these bacteria are not susceptible to high osmolarity, which suggests they're not Streptococcus species, like Streptococcus pneumoniae or Streptococcus pyogenes. Instead, these might be more like Enterococcus or some other non-susceptible species.\n\nSo, what do we know about these bacteria? Enterococcus species are known for being resistant to high osmolarity, which matches our findings here. They are gram-positive, catalase-negative, and can be hemolytic. That fits perfectly with what we're seeing in the blood cultures.\n\nNow, thinking about what's causing this infection, we need to consider the predisposing factors. For a 59-year-old man with these symptoms, it's likely an underlying medical condition that's allowing this infection to take hold. The presence of a vegetation on the aortic valve suggests that he might have had some underlying heart condition that's predisposed him to this infection.\n\nGiven that we're dealing with Enterococcus species, these are more likely to cause infections in individuals with certain comorbidities. For example, if he has an underlying heart condition, like aortic valve disease, that's definitely a risk factor. The presence of a vegetation could indicate that he already has a condition that's making his heart susceptible to this infection.\n\nNow, let's think about why Enterococcus might be involved. These bacteria are known for being hospital-acquired organisms, often due to antibiotic use. If he's been on antibiotics recently, that could have led to the selection of resistant organisms like Enterococcus. But, given the size of the vegetation and the fact that he's 59, it's more likely that he has an underlying heart condition that's facilitating this infection.\n\nSo, in this case, the most likely predisposing factor is that he has an underlying heart condition that's allowed the infection to take hold, particularly on the aortic valve with the presence of a large vegetation. This suggests he has aortic valve disease, which is putting him at risk for this specific infection.\n</think>\nThe most likely predisposing factor for this patient's condition is the presence of an underlying heart condition, particularly aortic valve disease. The 12 mm vegetation on the aortic valve, combined with the symptoms of fever, chills, night sweats, and generalized fatigue, suggests that the infection has taken hold due to the presence of aortic valve disease. This condition likely facilitated the infection caused by gram-positive, catalase-negative, gamma-hemolytic cocci in chains, which are resistant to high osmolarity and typically associated with hospital-acquired infections.<｜end▁of▁sentence｜>\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}